
     Program PW2BGW v.7.1 starts on  5Jun2023 at 22:47:54 

     This program is part of the open-source Quantum ESPRESSO suite
     for quantum simulation of materials; please cite
         "P. Giannozzi et al., J. Phys.:Condens. Matter 21 395502 (2009);
         "P. Giannozzi et al., J. Phys.:Condens. Matter 29 465901 (2017);
         "P. Giannozzi et al., J. Chem. Phys. 152 154105 (2020);
          URL http://www.quantum-espresso.org", 
     in publications or presentations arising from this work. More details at
     http://www.quantum-espresso.org/quote

     Parallel version (MPI & OpenMP), running on     144 processor cores
     Number of MPI processes:                72
     Threads/MPI process:                     2

     MPI processes distributed on     1 nodes
     K-points division:     npool     =      36
     R & G space division:  proc/nbgrp/npool/nimage =       2
     474525 MiB available memory on the printing compute node when the environment starts


     Reading xml data from directory:

     ./WS2.save/

     IMPORTANT: XC functional enforced from input :
     Exchange-correlation= PW
                           (   1   4   0   0   0   0   0)
     Any further DFT definition will be discarded
     Please, verify this is what you really want


     Parallelization info
     --------------------
     sticks:   dense  smooth     PW     G-vecs:    dense   smooth      PW
     Min          99      99     36                 8831     8831    2002
     Max         100     100     37                 8842     8842    2017
     Sum         199     199     73                17673    17673    4019

     Using Slab Decomposition

     Reading collected, re-writing distributed wavefunctions

     NLCC is present

     call write_wfng
     done write_wfng

     call write_vxc_r
     done write_vxc_r


     write_wfng   :      0.05s CPU      0.10s WALL (       1 calls)
     write_vxc_r  :      0.22s CPU      0.19s WALL (       1 calls)

     PW2BGW       :      0.67s CPU      0.81s WALL


   This run was terminated on:  22:47:54   5Jun2023            

=------------------------------------------------------------------------------=
   JOB DONE.
=------------------------------------------------------------------------------=
